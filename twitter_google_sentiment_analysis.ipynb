{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Check Python version exist in your system and if you don't have python use command below."
      ],
      "metadata": {
        "id": "eemXO7xG85wY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaqfiH329G6S",
        "outputId": "27da8071-fac7-4ca4-8f54-f28a8ef27d52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python is already the newest version (2.7.15~rc1-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "attPDZ90cIcC",
        "outputId": "0f858807-0ec8-4e6e-cd13-40a77b83622e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Install data parsing library bs4 to get import BeautifulSoup according to your python version."
      ],
      "metadata": {
        "id": "xC5mriUy9aFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bs4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvFpTsM-9jyi",
        "outputId": "7c230aa6-9f40-42a1-efd1-076e71924ad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Install Tweepy to get access of Twitter API."
      ],
      "metadata": {
        "id": "YbukfGDL96xJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tweepy "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMlpTlKF9qew",
        "outputId": "b67ae07c-bf72-41a9-c1f0-5eef38fabefd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.7/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.3.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.15.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (3.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Install lxml to allows easy handling of XML file, and can also be used for web scraping."
      ],
      "metadata": {
        "id": "A2aLDU6o-Th3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lxml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl2xrTxr97ze",
        "outputId": "7b9e102e-6f80-499e-d96c-ed2b09600730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (4.2.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Install transformers use for hugging face to perform sentiment analysis."
      ],
      "metadata": {
        "id": "MFzyROtr-hiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers"
      ],
      "metadata": {
        "id": "uFHDEkNQ-BLe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7bd8172-77b9-47f3-aefe-3d5784c26286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.8 MB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 11.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 30.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 40.8 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Import all the libraries which we install."
      ],
      "metadata": {
        "id": "Gu2JZFuP_ta9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ssl\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup as soup\n",
        "import tweepy\n",
        "from transformers import pipeline\n",
        "\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOkxk1g5-ipS",
        "outputId": "8e7cab52-e114-4ba8-ce68-0296089892e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a function to get access of twitter api and tweets fetching.\n",
        "#### How to get twitter API\n",
        "i) You have to open url 'https://developer.twitter.com/' \\\n",
        "ii) SignUp using your existing twitter account, if you don't have twitter account firstly create it using 'https://twitter.com/' \\\n",
        "iii) Go to dashboard and create app \\\n",
        "iv) Fill required details, make sure you are email and contact number verified. \\\n",
        "v) There you can get your api's \\\n",
        "vi) Where you have to copy (API Key and Secret) from Consumer Keys and (Access Token and Secret) from Authentication Tokens. \\\n",
        "vii) Make sure it has to elevated access to get the data from twitter."
      ],
      "metadata": {
        "id": "pgtfkP1U_1ZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def twitter_news(keyword,columns):\n",
        "    twd=[]\n",
        "    # Access Twitter API \n",
        "    ak = ['Paste your api_key here']\n",
        "    aks = ['Paste your api_key_secret here']\n",
        "    at = ['Paste your access_key here']\n",
        "    ats = ['Paste your access_key_secret here']\n",
        "    # Authentication Twitter API\n",
        "    auth = tweepy.OAuthHandler(ak, aks)\n",
        "    auth.set_access_token(at, ats)\n",
        "    api = tweepy.API(auth)\n",
        "    tweets_parse = tweepy.Cursor(api.search, q=keyword, count=100, tweet_mode='extended').items(6000)\n",
        "    for tweet in tweets_parse:\n",
        "        twd.append([tweet.created_at,tweet.full_text,tweet.user.screen_name])\n",
        "    twitter_df = pd.DataFrame(twd, columns=columns)\n",
        "    return twitter_df"
      ],
      "metadata": {
        "id": "W8zTy7-9w_uW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a function for google news fetching using bs4(soup)."
      ],
      "metadata": {
        "id": "N3efARTnCcuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def google_news(xml_news_url,columns):\n",
        "    google_data=[]\n",
        "    context = ssl._create_unverified_context()\n",
        "    Client = urlopen(xml_news_url, context=context)\n",
        "    xml_page = Client.read()\n",
        "    Client.close()\n",
        "    soup_page = soup(xml_page, \"xml\")\n",
        "    news_list = soup_page.findAll(\"item\")\n",
        "    # Parse February data\n",
        "    for news in news_list:\n",
        "        if \"Feb\" in news.pubDate.text:\n",
        "            google_data.append([news.pubDate.text,news.title.text,news.link.text])\n",
        "    google_df=pd.DataFrame(google_data,columns=columns)\n",
        "    return google_df"
      ],
      "metadata": {
        "id": "CBiVnrvl-5PQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create function for sentiment analysis."
      ],
      "metadata": {
        "id": "Q8TV3KZpCwNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_analysis(df):\n",
        "  l,l1=[],[]\n",
        "  for i in df['Tweet content/news headline']:\n",
        "    l+=[sentiment_pipeline(i)[0]['label']] \n",
        "    l1+=[sentiment_pipeline(i)[0]['score']] \n",
        "  df['label'] = l\n",
        "  df['score'] = l1\n",
        "  return df"
      ],
      "metadata": {
        "id": "R5HRjuLK-5dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Call Both the function(twitter_news and google_news) and concatinate it and perform sentiment analysis.\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "QNFmUSX8FIB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['Date of News/Twitter','Tweet content/news headline','source of news / person name who has tweeted']\n",
        "twitter_keyword = 'Green Hydrogen'\n",
        "google_url = 'https://news.google.com/rss/search?q=Green+Hydrogen+when:35d&hl=en-IN&gl=IN&ceid=IN:en'\n",
        "for_twi_news = twitter_news(twitter_keyword,columns)\n",
        "for_google_news = google_news(google_url,columns)\n",
        "result = [for_twi_news,for_google_news]\n",
        "df = pd.concat(result,ignore_index=True)\n",
        "overall_data = sentiment_analysis(df)\n",
        "overall_data"
      ],
      "metadata": {
        "id": "UAw7r0I64Jeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_data.to_csv('twitter_google_data.csv',index=False)"
      ],
      "metadata": {
        "id": "bkCKqEJBTeH3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "twitter_google_sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}